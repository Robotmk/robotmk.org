---
draft: false
title: "RoboCon 2026 - Recap (Part 6 - Friday)"
# --- Italic subheading
# lead: 
# -- giscus id to match comments
commentid: robocon26-recap-6
# slug: 
# -- for posts in menubar, use this (shorter) title
# menutitle: 
description: null
date: "2026-02-14T10:04:33+02:00"
categories:
  - news
tags:
  - "robocon"
authorbox: true
sidebar: true
pager: false
thumbnail: "img/robocon.png"
---

This is **Part 6** of the six-part review of RoboCon 2026 in Helsinki.


<!--more-->


---

âž› Back to **[Part 5 (Friday: Conference Day 2)]({{< ref "/robocon26-recap-5/" >}})**

---

## Friday: Conference Day 2

### How AI tools affect learning and the implications on open source tools

{{< portrait src="img/arttu.png" alt="Arttu Taipale" >}}

**Arttu Taipale** is an automation developer at Knowit Solutions and uses Robot Framework daily in both RPA and test automation projects. He is a passionate open source enthusiast with a strong problem-solving instinct. He has been offering Robot Framework training for four years â€“ an experience that has given him direct insight into how **learning is changing in the GenAI era**.

His session posed a fundamental question:  
**How do we learn software development when GenAI tools are increasingly writing the code for us?**

The **challenge** is real: ChatGPT easily passes physics exams at British universities (as a study at the University of Hull showed), and companies report that more code is generated by GenAI than written manually.

The core of his argument was based on **learning theory** â€“ illustrated by Star Wars metaphors that worked surprisingly well: **receiving** (taking in new information) versus **retrieval** (recalling and applying knowledge).  
Luke Skywalker, picking up a lightsaber for the first time, represented the novice.  
Only through practice against the droid in the Millennium Falcon â€“ through active **retrieval** â€“ is knowledge anchored.

The problem with AI tools: they make receiving much easier, **but undermine retrieval**.  
When we outsource code generation, we stop consolidating connections in the brain.  

Worse still, we make **the wrong mistakes**.  
Arttu showed (deliberately exaggerated) examples from his training sessions where participants tried to solve problems with AI. The result: outdated syntax, overly complicated solutions or keywords from the wrong libraries.  
For beginners â€“ who don't yet have mental models â€“ these mistakes offer no basis for learning.

The key warning: a **divergence between learning and doing** arises.  
Junior developers could use GenAI to master the simple tasks that should actually be the basis of their training â€“ only to then fall into a knowledge gap when faced with complex problems where AI does not help. "*Imagine Luke Skywalker telling C3PO to fight all his fights until the final movie*" â€“ he would have had no chance against Darth Vader. 

His recommendation was clear, but uncomfortable: **we must learn the same things as before** â€“ with the same depth.  
AI tools are productivity multipliers for those who already understand what they are building.  

The best way to master AI use? His recommendation: **read books**. Because prompting requires understanding what you are asking â€“ and critical thinking when analysing the answers.

Finally, Arttu turned his attention to **Robot Framework itself**: Will it remain a tool that can be used efficiently with GenAI? Or will other tools gain the upper hand?  
The open-source nature of Robot Framework is an advantage, but the skewed training data of LLMs (often with outdated syntax) poses a real challenge.

ðŸ‘‰ **Conclusion**  
One of the **most thought-provoking sessions of the conference**.  
Arttu skilfully navigated between pragmatism and critical reflection.  
His message: AI is **no substitute for in-depth knowledge** â€“ it is a tool for those who already know how to wield the hammer.  
The community must actively work to ensure that Robot Framework remains relevant in the AI era â€“ not by resisting AI, but through better integration and updated learning resources.

---

### PlatynUI: Cross-platform desktop UI automation for Robot Framework


{{< portrait src="img/daniel.png" alt="Daniel Biehl" >}}

**Daniel Biehl** presented [PlatynUI](https://github.com/imbus/platynui-sut), a library that makes **desktop UI automation** consistent across platforms on Windows, Linux and macOS.  

PlatynUI addresses a problem familiar to anyone who has ever written desktop tests: it is not easy, especially for beginners, to write robust tests with it.  
**Timing** issues, **focus** problems, **asynchronous UIs** â€“ desktop automation is inherently a bit of a pain.  

And so it happens that, out of sheer desperation, people work with `Sleep`s, buttons are clicked in rapid succession in `FOR` loops, etc. These are all workarounds for a deeper problem.

Daniel explained this using the keyword `Click`:

- What do we **expect**? That the application responds as if a user had clicked.  
- What does the keyword **do**? It simply fires a single mouse event at a coordinate â€“ without checking whether the element is visible, activated or focused. A click is therefore only a *suggestion*, not a guarantee.

Instead of keywords for mechanisms such as "Click", PlatynUI offers **semantic actions**: Keywords such as `Activate`, `Focus`, `Check` or `Select` describe the *intent* â€“ the desired result.  
Each of these actions follows a clear pattern:  

- **Preconditions**: Window active, element in viewport, element enabled? 
- **Perform**: Execute the action. 
- **Postcondition**: Wait until the application is ready.  

This may sound familiar to some: Playwright, which works in the [BrowserLibrary](https://marketsquare.github.io/robotframework-browser/Browser.html), uses a similar approach with its [actionability checks](https://playwright.dev/docs/actionability). Here, too, a button can only be clicked if the actionability checks have determined that the element is visible/active and not covered by another element.

**PlatynUI is still under development** â€“ tooling, keywords and platform coverage are not yet finalised.  
However, the project already demonstrates a solid, principle-driven approach to a chronic problem in desktop automation.  
And as I wrote in my review of the **PlatynUI workshop** above: if companies such as **German Air Traffic Control** are already using PlatynUI productively, this indicates that it is sufficiently mature. 

ðŸ‘‰ **Conclusion**  
PlatynUI is not the solution to all problems: especially in synthetic monitoring, there will always be use cases where image comparison libraries are the only solution (e.g. RDP/Citrix).  
But in all other cases, PLatynUI will be a real game changer with its "*Robot Framework First*" approach.  
(If you are interested in training, please contact me; I am currently working on the material.)


---

### After RoboCon is before RoboCon

The week had flown by once again.  
Four days full of presentations, discussions and new ideas â€“ and suddenly I was back on the plane home, my head full of ideas and a collection of notes (which I have finally processed in this blog article ðŸ¤— ).

![alt text](img/airport.png)

What makes RoboCon special for me is how many topics intertwine â€“ from AI to test architecture to infrastructure â€“ and paint an increasingly clear picture of where the ecosystem is heading.

![alt text](img/stage.png)

I will certainly be pursuing some of the approaches in the coming months. Others may only become apparent with a little distance.  
That is precisely the value of such events: they provide **impulses that linger**.

Perhaps this review will convince one or two of you to attend in 2027.

Feel free to write in the comments below how you liked it. 

**After RoboCon is before RoboCon!**




---

âž› Back to [Part 1 (Tuesday/Wednesday, Workshop & Community Day)]({{< ref "/robocon26-recap-1/" >}})  
âž› Back to [Part 5 (Friday: Conference Day 2)]({{< ref "/robocon26-recap-5/" >}})
